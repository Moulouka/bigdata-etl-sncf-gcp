{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 3 : Analyse pour la Construction de la Couche Gold\n",
        "\n",
        "## Objectif\n",
        "\n",
        "Ce notebook vous guide dans l'**analyse des données de la couche silver** pour préparer la construction de la couche **gold** (analytics/BI/ML).\n",
        "\n",
        "La couche gold contient des données transformées, nettoyées et optimisées pour l'analyse métier et la création de rapports/dashboards.\n",
        "\n",
        "## Prérequis\n",
        "\n",
        "Avant d'exécuter ce notebook, assurez-vous d'avoir :\n",
        "\n",
        "1. **Exécuté le notebook `2_[LOAD]_load_to_bigquery.ipynb`** pour avoir toutes les tables dans BigQuery (dataset `silver`)\n",
        "2. **Fichier `.env` configuré** avec les variables d'environnement nécessaires\n",
        "3. **Service Account** avec les permissions BigQuery (`BigQuery Data Viewer`, `BigQuery Job User`)\n",
        "4. **Packages Python installés** : `google-cloud-bigquery`, `pandas`, etc.\n",
        "\n",
        "## Structure du Notebook\n",
        "\n",
        "Ce notebook contient **4 tâches principales** à réaliser :\n",
        "\n",
        "1. **Tâche 1 : Analyser la Granularité** - Comprendre le niveau de détail de chaque table\n",
        "2. **Tâche 2 : Identifier les Transformations** - Déterminer les transformations nécessaires pour la couche gold\n",
        "3. **Tâche 3 : Identifier les Clés de Jointure** - Mapper les relations entre les tables\n",
        "4. **Tâche 4 : Analyse métier Identifier les **KPIs** métiers - \n",
        "\n",
        "## Résultats Attendus\n",
        "\n",
        "À la fin de ce notebook, vous devriez avoir :\n",
        "- Une compréhension claire de la structure et de la granularité de chaque table\n",
        "- Une liste des transformations à appliquer pour créer la couche gold\n",
        "- Un schéma de jointures documenté"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration et Connexion à BigQuery\n",
        "\n",
        "Cette section configure l'environnement et établit la connexion avec BigQuery pour explorer les données de la couche silver.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] - Connecté au projet: big-data-projet-sncf\n",
            "[OK] - Dataset: silver\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Third-party imports\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Configuration\n",
        "load_dotenv()\n",
        "\n",
        "ROOT = Path.cwd().parent\n",
        "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
        "SA_PATH = ROOT / os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
        "DATASET_ID = \"silver\"\n",
        "\n",
        "# Authentification\n",
        "creds = service_account.Credentials.from_service_account_file(SA_PATH)\n",
        "bq_client = bigquery.Client(project=PROJECT_ID, credentials=creds)\n",
        "\n",
        "print(f\"[OK] - Connecté au projet: {PROJECT_ID}\")\n",
        "print(f\"[OK] - Dataset: {DATASET_ID}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tâche 1 : Analyser la Granularité de Chaque Table\n",
        "\n",
        "### Objectif\n",
        "\n",
        "La **granularité** d'une table correspond au niveau de détail des données qu'elle contient. Comprendre la granularité est essentiel pour :\n",
        "- Déterminer comment agréger les données\n",
        "- Identifier les duplications potentielles\n",
        "- Comprendre le niveau de détail nécessaire pour les analyses métier\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Pour chaque table du dataset `silver`, vous devez :\n",
        "\n",
        "1. **Lister les colonnes** et leurs types\n",
        "2. **Identifier les clés primaires** ou les colonnes qui identifient de manière unique une ligne\n",
        "3. **Déterminer la granularité** : à quel niveau de détail sont les données ?\n",
        "   - Exemple : `fact_validations` pourrait être au niveau **jour × gare × type de titre**\n",
        "4. **Compter les lignes** et estimer la taille des données\n",
        "5. **Identifier les colonnes de dimension** (références vers d'autres tables)\n",
        "\n",
        "### Exemple de Format de Réponse\n",
        "\n",
        "```\n",
        "Table: dim_gare\n",
        "- Granularité: 1 ligne = 1 gare\n",
        "- Clé primaire: id_gares\n",
        "- Nombre de lignes: 1234\n",
        "- Colonnes de dimension: aucune (table de dimension)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### À Compléter : Analyse de Granularité\n",
        "\n",
        "**Tables de Dimension :**\n",
        "\n",
        "1. `dim_gare`\n",
        "2. `dim_ligne`\n",
        "3. `dim_arret`\n",
        "4. `dim_vacances_scolaires`\n",
        "5. `dim_transporteur`\n",
        "\n",
        "**Tables de Fait :**\n",
        "\n",
        "6. `fact_validations_*` (toutes les tables de validation)\n",
        "\n",
        "**Votre tâche :** Exécutez des requêtes SQL pour analyser chaque table et remplir le tableau ci-dessous.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Analyse de dim_gare ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\moham\\Master 2 - CS\\BigData\\ProjetFinal\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nb_lignes</th>\n",
              "      <th>nb_gares_uniques</th>\n",
              "      <th>nb_id_null</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1240</td>\n",
              "      <td>1237</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nb_lignes  nb_gares_uniques  nb_id_null\n",
              "0       1240              1237           0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Schéma ===\n",
            "  - geo_point_2d: GEOGRAPHY (NULLABLE)\n",
            "  - geo_shape: GEOGRAPHY (NULLABLE)\n",
            "  - id_gares: INTEGER (REQUIRED)\n",
            "  - nom_gares: STRING (NULLABLE)\n",
            "  - nom_so_gar: STRING (NULLABLE)\n",
            "  - nom_su_gar: STRING (NULLABLE)\n",
            "  - id_ref_zdc: INTEGER (NULLABLE)\n",
            "  - nom_zdc: STRING (NULLABLE)\n",
            "  - id_ref_zda: INTEGER (NULLABLE)\n",
            "  - nom_zda: STRING (NULLABLE)\n",
            "  - idrefliga: STRING (NULLABLE)\n",
            "  - idrefligc: STRING (NULLABLE)\n",
            "  - res_com: STRING (NULLABLE)\n",
            "  - indice_lig: STRING (NULLABLE)\n",
            "  - mode: STRING (NULLABLE)\n",
            "  - tertrain: STRING (NULLABLE)\n",
            "  - terrer: STRING (NULLABLE)\n",
            "  - termetro: STRING (NULLABLE)\n",
            "  - tertram: STRING (NULLABLE)\n",
            "  - terval: STRING (NULLABLE)\n",
            "  - exploitant: STRING (NULLABLE)\n",
            "  - idf: INTEGER (NULLABLE)\n",
            "  - principal: INTEGER (NULLABLE)\n",
            "  - x: FLOAT (NULLABLE)\n",
            "  - y: FLOAT (NULLABLE)\n",
            "  - picto: STRING (NULLABLE)\n",
            "  - nom_iv: STRING (NULLABLE)\n"
          ]
        }
      ],
      "source": [
        "# Exemple : Analyser la table dim_gare\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNT(*) AS nb_lignes,\n",
        "  COUNT(DISTINCT id_gares) AS nb_gares_uniques,\n",
        "  COUNTIF(id_gares IS NULL) AS nb_id_null\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.gares`\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Analyse de dim_gare ===\")\n",
        "display(df)\n",
        "\n",
        "# Afficher le schéma\n",
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.gares\")\n",
        "print(\"\\n=== Schéma ===\")\n",
        "for field in table.schema:\n",
        "    print(f\"  - {field.name}: {field.field_type} ({field.mode})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyse – table gares\n",
        "\n",
        "La table gares contient les informations descriptives sur les gares de SNCF.\n",
        "Chaque gare est identifiée par la colonne id_gares.\n",
        "\n",
        "On observe :\n",
        "- 1240 lignes au total\n",
        "- 1237 identifiants de gares distincts\n",
        "- aucune valeur NULL sur la colonne id_gares\n",
        "\n",
        "La différence entre le nombre de lignes et le nombre de gares distinctes indique la présence de quelques doublons.\n",
        "La granularité de cette table est donc : **1 ligne = 1 gare**.\n",
        "\n",
        "Il s’agit d’une table de dimension.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id_line STRING\n",
            "name_line STRING\n",
            "shortname_line STRING\n",
            "transportmode STRING\n",
            "transportsubmode STRING\n",
            "type STRING\n",
            "operatorref STRING\n",
            "operatorname STRING\n",
            "additionaloperators STRING\n",
            "networkname STRING\n",
            "colourweb_hexa STRING\n",
            "textcolourweb_hexa STRING\n",
            "colourprint_cmjn STRING\n",
            "textcolourprint_hexa STRING\n",
            "accessibility STRING\n",
            "audiblesigns_available STRING\n",
            "visualsigns_available STRING\n",
            "id_groupoflines STRING\n",
            "shortname_groupoflines STRING\n",
            "notice_title STRING\n",
            "notice_text STRING\n",
            "picto STRING\n",
            "valid_fromdate DATE\n",
            "valid_todate DATE\n",
            "status STRING\n",
            "privatecode STRING\n",
            "air_conditioning STRING\n",
            "id_bus_contrat INTEGER\n"
          ]
        }
      ],
      "source": [
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_ligne\")\n",
        "\n",
        "for field in table.schema:\n",
        "    print(field.name, field.field_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\moham\\Master 2 - CS\\BigData\\ProjetFinal\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Analyse de dim_ligne ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nb_lignes</th>\n",
              "      <th>nb_lignes_uniques</th>\n",
              "      <th>nb_id_null</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2116</td>\n",
              "      <td>2116</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nb_lignes  nb_lignes_uniques  nb_id_null\n",
              "0       2116               2116           0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Schéma ===\n",
            "  - id_line: STRING (NULLABLE)\n",
            "  - name_line: STRING (NULLABLE)\n",
            "  - shortname_line: STRING (NULLABLE)\n",
            "  - transportmode: STRING (NULLABLE)\n",
            "  - transportsubmode: STRING (NULLABLE)\n",
            "  - type: STRING (NULLABLE)\n",
            "  - operatorref: STRING (NULLABLE)\n",
            "  - operatorname: STRING (NULLABLE)\n",
            "  - additionaloperators: STRING (NULLABLE)\n",
            "  - networkname: STRING (NULLABLE)\n",
            "  - colourweb_hexa: STRING (NULLABLE)\n",
            "  - textcolourweb_hexa: STRING (NULLABLE)\n",
            "  - colourprint_cmjn: STRING (NULLABLE)\n",
            "  - textcolourprint_hexa: STRING (NULLABLE)\n",
            "  - accessibility: STRING (NULLABLE)\n",
            "  - audiblesigns_available: STRING (NULLABLE)\n",
            "  - visualsigns_available: STRING (NULLABLE)\n",
            "  - id_groupoflines: STRING (NULLABLE)\n",
            "  - shortname_groupoflines: STRING (NULLABLE)\n",
            "  - notice_title: STRING (NULLABLE)\n",
            "  - notice_text: STRING (NULLABLE)\n",
            "  - picto: STRING (NULLABLE)\n",
            "  - valid_fromdate: DATE (NULLABLE)\n",
            "  - valid_todate: DATE (NULLABLE)\n",
            "  - status: STRING (NULLABLE)\n",
            "  - privatecode: STRING (NULLABLE)\n",
            "  - air_conditioning: STRING (NULLABLE)\n",
            "  - id_bus_contrat: INTEGER (NULLABLE)\n"
          ]
        }
      ],
      "source": [
        "# Analyser la table dim_ligne\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNT(*) AS nb_lignes,\n",
        "  COUNT(DISTINCT id_line) AS nb_lignes_uniques,\n",
        "  COUNTIF(id_line IS NULL) AS nb_id_null\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.dim_ligne`\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Analyse de dim_ligne ===\")\n",
        "display(df)\n",
        "\n",
        "# Afficher le schéma\n",
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_ligne\")\n",
        "print(\"\\n=== Schéma ===\")\n",
        "for field in table.schema:\n",
        "    print(f\"  - {field.name}: {field.field_type} ({field.mode})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyse – table dim_ligne\n",
        "\n",
        "La table dim_ligne contient les informations descriptives des lignes de transport\n",
        "(métro, RER, bus, tram, etc.).\n",
        "\n",
        "Chaque ligne est identifiée par la colonne id_ligne.\n",
        "\n",
        "On observe :\n",
        "- 2116 lignes au total\n",
        "- 2116 lignes distinctes\n",
        "- aucune valeur NULL sur l’identifiant\n",
        "\n",
        "La granularité de cette table est donc :\n",
        "**1 ligne = 1 ligne de transport**.\n",
        "\n",
        "Il s’agit d’une table de dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arrid STRING\n",
            "arrversion STRING\n",
            "arrcreated TIMESTAMP\n",
            "arrchanged TIMESTAMP\n",
            "arrname STRING\n",
            "arrtype STRING\n",
            "arrxepsg2154 INTEGER\n",
            "arryepsg2154 INTEGER\n",
            "arrtown STRING\n",
            "arrpostalregion STRING\n",
            "arraccessibility STRING\n",
            "arraudiblesignals STRING\n",
            "arrvisualsigns STRING\n",
            "arrfarezone STRING\n",
            "zdaid STRING\n",
            "arrgeopoint GEOGRAPHY\n"
          ]
        }
      ],
      "source": [
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_arret\")\n",
        "\n",
        "for field in table.schema:\n",
        "    print(field.name, field.field_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\moham\\Master 2 - CS\\BigData\\ProjetFinal\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Analyse de dim_arrêt ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nb_lignes</th>\n",
              "      <th>nb_arret_uniques</th>\n",
              "      <th>nb_id_null</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38368</td>\n",
              "      <td>38368</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nb_lignes  nb_arret_uniques  nb_id_null\n",
              "0      38368             38368           0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Schéma ===\n",
            "  - arrid: STRING (NULLABLE)\n",
            "  - arrversion: STRING (NULLABLE)\n",
            "  - arrcreated: TIMESTAMP (NULLABLE)\n",
            "  - arrchanged: TIMESTAMP (NULLABLE)\n",
            "  - arrname: STRING (NULLABLE)\n",
            "  - arrtype: STRING (NULLABLE)\n",
            "  - arrxepsg2154: INTEGER (NULLABLE)\n",
            "  - arryepsg2154: INTEGER (NULLABLE)\n",
            "  - arrtown: STRING (NULLABLE)\n",
            "  - arrpostalregion: STRING (NULLABLE)\n",
            "  - arraccessibility: STRING (NULLABLE)\n",
            "  - arraudiblesignals: STRING (NULLABLE)\n",
            "  - arrvisualsigns: STRING (NULLABLE)\n",
            "  - arrfarezone: STRING (NULLABLE)\n",
            "  - zdaid: STRING (NULLABLE)\n",
            "  - arrgeopoint: GEOGRAPHY (NULLABLE)\n"
          ]
        }
      ],
      "source": [
        "# Analyser la table dim_arrêt\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNT(*) AS nb_lignes,\n",
        "  COUNT(DISTINCT arrid) AS nb_arret_uniques,\n",
        "  COUNTIF(arrid IS NULL) AS nb_id_null\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.dim_arret`\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Analyse de dim_arrêt ===\")\n",
        "display(df)\n",
        "\n",
        "# Afficher le schéma\n",
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_arret\")\n",
        "print(\"\\n=== Schéma ===\")\n",
        "for field in table.schema:\n",
        "    print(f\"  - {field.name}: {field.field_type} ({field.mode})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyse – table dim_arret\n",
        "\n",
        "La table **dim_arret** contient les informations descriptives sur les arrêts du réseau.\n",
        "\n",
        "Chaque arrêt est identifié par la colonne arrid.\n",
        "\n",
        "On observe :\n",
        "- 38 368 lignes au total\n",
        "- 38 368 arrêts distincts\n",
        "- aucune valeur NULL sur l’identifiant\n",
        "\n",
        "Le nombre de lignes est égal au nombre d’identifiants distincts, ce qui veut dire qu'il n'y a aucun doublons ici.\n",
        "\n",
        "La granularité de cette table est :\n",
        "**1 ligne = 1 arrêt**.\n",
        "\n",
        "Il s’agit d’une table de dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "description STRING\n",
            "population STRING\n",
            "start_date TIMESTAMP\n",
            "end_date TIMESTAMP\n",
            "location STRING\n",
            "zones STRING\n",
            "annee_scolaire STRING\n"
          ]
        }
      ],
      "source": [
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_vacances_scolaires\")\n",
        "\n",
        "for field in table.schema:\n",
        "    print(field.name, field.field_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Analyse de dim_vacances_scolaires ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\moham\\Master 2 - CS\\BigData\\ProjetFinal\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nb_lignes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nb_lignes\n",
              "0       2320"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Schéma ===\n",
            "  - description: STRING (NULLABLE)\n",
            "  - population: STRING (NULLABLE)\n",
            "  - start_date: TIMESTAMP (NULLABLE)\n",
            "  - end_date: TIMESTAMP (NULLABLE)\n",
            "  - location: STRING (NULLABLE)\n",
            "  - zones: STRING (NULLABLE)\n",
            "  - annee_scolaire: STRING (NULLABLE)\n"
          ]
        }
      ],
      "source": [
        "# Analyser la table dim_vacances_scolaires\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNT(*) AS nb_lignes\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.dim_vacances_scolaires`\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Analyse de dim_vacances_scolaires ===\")\n",
        "display(df)\n",
        "\n",
        "# Afficher le schéma\n",
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_vacances_scolaires\")\n",
        "print(\"\\n=== Schéma ===\")\n",
        "for field in table.schema:\n",
        "    print(f\"  - {field.name}: {field.field_type} ({field.mode})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyse – table dim_vacances_scolaires\n",
        "\n",
        "La table dim_vacances_scolaires contient des informations sur les périodes de vacances scolaires.\n",
        "\n",
        "Chaque ligne correspond à une période de vacances pour une zone donnée et une année scolaire.\n",
        "\n",
        "On observe :\n",
        "- 2 320 lignes au total\n",
        "\n",
        "Les principales informations présentes dans la table sont :\n",
        "- le type de vacances (description)\n",
        "- la population concernée\n",
        "- la date de début et la date de fin\n",
        "- la zone géographique\n",
        "- l’année scolaire\n",
        "\n",
        "Il n’existe pas d’identifiant unique simple pour cette table.\n",
        "L’identification d’une ligne se fait en combinant plusieurs colonnes\n",
        "(zone, dates et année scolaire).\n",
        "\n",
        "La granularité est donc :\n",
        "**1 ligne = 1 période de vacances × 1 zone × 1 année scolaire**.\n",
        "\n",
        "Il s’agit d’une table de dimension temporelle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "operatorname STRING\n",
            "operatorref STRING\n",
            "housenumber STRING\n",
            "street STRING\n",
            "addressline1 STRING\n",
            "town STRING\n",
            "postcode STRING\n",
            "postcodeextension STRING\n",
            "phone STRING\n",
            "url STRING\n",
            "furtherdetails STRING\n",
            "contactperson STRING\n",
            "logo STRING\n",
            "email STRING\n"
          ]
        }
      ],
      "source": [
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_transporteur\")\n",
        "\n",
        "for field in table.schema:\n",
        "    print(field.name, field.field_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Analyse de dim_transporteur ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\moham\\Master 2 - CS\\BigData\\ProjetFinal\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nb_lignes</th>\n",
              "      <th>nb_transporteurs_uniques</th>\n",
              "      <th>nb_id_null</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nb_lignes  nb_transporteurs_uniques  nb_id_null\n",
              "0         54                        54           0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Schéma ===\n",
            "  - operatorname: STRING (NULLABLE)\n",
            "  - operatorref: STRING (NULLABLE)\n",
            "  - housenumber: STRING (NULLABLE)\n",
            "  - street: STRING (NULLABLE)\n",
            "  - addressline1: STRING (NULLABLE)\n",
            "  - town: STRING (NULLABLE)\n",
            "  - postcode: STRING (NULLABLE)\n",
            "  - postcodeextension: STRING (NULLABLE)\n",
            "  - phone: STRING (NULLABLE)\n",
            "  - url: STRING (NULLABLE)\n",
            "  - furtherdetails: STRING (NULLABLE)\n",
            "  - contactperson: STRING (NULLABLE)\n",
            "  - logo: STRING (NULLABLE)\n",
            "  - email: STRING (NULLABLE)\n"
          ]
        }
      ],
      "source": [
        "# Analyser la table dim_transporteur\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNT(*) AS nb_lignes,\n",
        "  COUNT(DISTINCT operatorref) AS nb_transporteurs_uniques,\n",
        "  COUNTIF(operatorref IS NULL) AS nb_id_null\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.dim_transporteur`\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Analyse de dim_transporteur ===\")\n",
        "display(df)\n",
        "\n",
        "# Afficher le schéma\n",
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_transporteur\")\n",
        "print(\"\\n=== Schéma ===\")\n",
        "for field in table.schema:\n",
        "    print(f\"  - {field.name}: {field.field_type} ({field.mode})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyse – table dim_transporteur\n",
        "\n",
        "La table dim_transporteur contient les informations descriptives sur les transporteurs.\n",
        "\n",
        "Chaque transporteur est identifié de manière logique par la colonne `operatorref`,\n",
        "qui correspond à un code opérateur.\n",
        "\n",
        "On observe :\n",
        "- 54 lignes au total\n",
        "- 54 transporteurs distincts\n",
        "- aucune valeur NULL sur l’identifiant\n",
        "\n",
        "Le nombre de lignes est égal au nombre de transporteurs distincts, pas de doublons.\n",
        "\n",
        "Il n’existe pas de clé primaire technique explicite dans cette table.\n",
        "La colonne `operatorref` est utilisée comme identifiant fonctionnel.\n",
        "\n",
        "La granularité de cette table est :\n",
        "**1 ligne = 1 transporteur**.\n",
        "\n",
        "Il s’agit d’une table de dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tâche 2 : Identifier les Transformations Nécessaires\n",
        "\n",
        "### Objectif\n",
        "\n",
        "Identifier les **transformations** à appliquer aux données de la couche silver pour créer la couche gold optimisée pour l'analyse.\n",
        "\n",
        "### Types de Transformations Possibles\n",
        "\n",
        "1. **Nettoyage des données**\n",
        "   - Suppression des doublons\n",
        "   - Gestion des valeurs NULL\n",
        "   - Normalisation des formats (dates, textes)\n",
        "\n",
        "2. **Enrichissement**\n",
        "   - Ajout de colonnes calculées\n",
        "   - Jointures avec les tables de dimension\n",
        "   - Ajout de catégories/segments\n",
        "\n",
        "3. **Agrégation**\n",
        "   - Regroupement par dimensions (jour, gare, ligne, etc.)\n",
        "   - Calcul de métriques (somme, moyenne, comptage)\n",
        "   - Création de tables pré-agrégées\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Pour chaque table, identifiez :\n",
        "1. **Les problèmes de qualité** à corriger\n",
        "2. **Les transformations nécessaires** avec des exemples concrets\n",
        "3. **Les colonnes à ajouter** (calculées ou issues de jointures)\n",
        "4. **Les agrégations possibles** pour optimiser les requêtes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JOUR DATE\n",
            "CODE_STIF_TRNS INTEGER\n",
            "CODE_STIF_RES INTEGER\n",
            "CODE_STIF_ARRET INTEGER\n",
            "LIBELLE_ARRET STRING\n",
            "ID_ZDC INTEGER\n",
            "CATEGORIE_TITRE STRING\n",
            "NB_VALD INTEGER\n"
          ]
        }
      ],
      "source": [
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.fact_validations_2023_s2_nb_fer_txt\")\n",
        "\n",
        "for field in table.schema:\n",
        "    print(field.name, field.field_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Transformation à prévoir pour la couche gold :**\n",
        "\n",
        "À partir du schéma de la table, plusieurs transformations sont nécessaires pour construire la couche gold.\n",
        "\n",
        "**1. Nettoyage des données**\n",
        "\n",
        "- Vérifier les éventuels doublons pour une même combinaison (jour, gare (ID_ZDC), catégorie de titre)\n",
        "\n",
        "- Vérifier la présence de valeurs NULL dans les colonnes importantes (JOUR, ID_ZDC, NB_VALD)\n",
        "\n",
        "- Supprimer ou ignorer les lignes où le nombre de validations est manquant\n",
        "\n",
        "Cela permet d’éviter de compter plusieurs fois les mêmes validations.\n",
        "\n",
        "**2. Normalisation et préparation des dates**\n",
        "\n",
        "- Extraire à partir de la colonne **JOUR** :\n",
        "  - l’année  \n",
        "  - le mois  \n",
        "  - le jour de la semaine  \n",
        "\n",
        "Ces informations permettront d’analyser l’évolution des validations dans le temps, par exemple par mois ou par jour.\n",
        "\n",
        "**3. Enrichissement par jointures**\n",
        "\n",
        "- Joindre la table avec les tables de dimension :\n",
        "    - dim_gare via ID_ZDC\n",
        "    - dim_ligne via CODE_SITE_LIGNE\n",
        "\n",
        "Cela permet d’obtenir des informations lisibles (nom de la gare, nom de la ligne) au lieu d’identifiants techniques.\n",
        "\n",
        "L'objectif final est d'obtenir une `table gold` plus lisible, plus propre et directement exploitable pour les tableaux de bord et les analyses métier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\moham\\Master 2 - CS\\BigData\\ProjetFinal\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Exemple : Recherche de doublons ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>JOUR</th>\n",
              "      <th>ID_ZDC</th>\n",
              "      <th>CATEGORIE_TITRE</th>\n",
              "      <th>nb_occurrences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-07-14</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-07-04</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-07-10</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-07-09</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-07-13</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2023-07-17</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2023-07-16</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2023-07-06</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2023-07-05</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2023-07-20</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2023-07-11</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2023-07-07</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2023-07-03</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2023-07-19</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2023-07-18</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2023-07-15</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2023-07-08</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2023-07-12</td>\n",
              "      <td>73626</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          JOUR  ID_ZDC CATEGORIE_TITRE  nb_occurrences\n",
              "0   2023-07-14   73626       Amethyste               3\n",
              "1   2023-07-04   73626       Amethyste               3\n",
              "2   2023-07-10   73626       Amethyste               3\n",
              "3   2023-07-09   73626       Amethyste               3\n",
              "4   2023-07-13   73626       Amethyste               3\n",
              "5   2023-07-17   73626       Amethyste               3\n",
              "6   2023-07-16   73626       Amethyste               3\n",
              "7   2023-07-02   73626       Amethyste               3\n",
              "8   2023-07-06   73626       Amethyste               3\n",
              "9   2023-07-05   73626       Amethyste               3\n",
              "10  2023-07-20   73626       Amethyste               3\n",
              "11  2023-07-11   73626       Amethyste               3\n",
              "12  2023-07-07   73626       Amethyste               3\n",
              "13  2023-07-03   73626       Amethyste               3\n",
              "14  2023-07-01   73626       Amethyste               3\n",
              "15  2023-07-19   73626       Amethyste               3\n",
              "16  2023-07-18   73626       Amethyste               3\n",
              "17  2023-07-15   73626       Amethyste               3\n",
              "18  2023-07-08   73626       Amethyste               3\n",
              "19  2023-07-12   73626       Amethyste               3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Exemple 1 : Vérifier les doublons dans fact_validations\n",
        "\n",
        "#fact_validations_2023\n",
        "TABLE_FACT = \"fact_validations_2023_s2_nb_fer_txt\"\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  JOUR,\n",
        "  ID_ZDC,\n",
        "  CATEGORIE_TITRE,\n",
        "  COUNT(*) AS nb_occurrences\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_FACT}`\n",
        "GROUP BY 1,2,3\n",
        "HAVING COUNT(*) > 1\n",
        "ORDER BY nb_occurrences DESC\n",
        "LIMIT 20\n",
        "\"\"\"\n",
        "\n",
        "df_duplicates = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Exemple : Recherche de doublons ===\")\n",
        "display(df_duplicates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On observe des doublons dans la table de validations : certaines combinaisons\n",
        "(JOUR, ID_ZDC, CATEGORIE_TITRE) apparaissent plusieurs fois.\n",
        "\n",
        "Exemple : pour ID_ZDC = 73626 et CATEGORIE_TITRE = \"Amethyste\",\n",
        "plusieurs jours ont nb_occurrences = 3, ce qui signifie que la même information\n",
        "est présente 3 fois dans la table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\moham\\Master 2 - CS\\BigData\\ProjetFinal\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Exemple : Vérification des valeurs NULL ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nb_jour_null</th>\n",
              "      <th>nb_id_zdc_null</th>\n",
              "      <th>nb_categorie_null</th>\n",
              "      <th>nb_nb_valid_null</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nb_jour_null  nb_id_zdc_null  nb_categorie_null  nb_nb_valid_null\n",
              "0             0               0                  0                 0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Exemple 2 : Vérifier les valeurs NULL\n",
        "\n",
        "#fact_validations_2023\n",
        "TABLE_FACT = \"fact_validations_2023_s2_nb_fer_txt\"\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNTIF(JOUR IS NULL) AS nb_jour_null,\n",
        "  COUNTIF(ID_ZDC IS NULL) AS nb_id_zdc_null,\n",
        "  COUNTIF(CATEGORIE_TITRE IS NULL) AS nb_categorie_null,\n",
        "  COUNTIF(NB_VALD IS NULL) AS nb_nb_valid_null\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_FACT}`\n",
        "\"\"\"\n",
        "\n",
        "df_nulls = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Exemple : Vérification des valeurs NULL ===\")\n",
        "display(df_nulls)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avons réalisés une vérification des valeurs manquantes sur les colonnes principales de la table de faits.\n",
        "\n",
        "Colonnes analysées :\n",
        "- JOUR\n",
        "- ID_ZDC\n",
        "- CATEGORIE_TITRE\n",
        "- NB_VALD\n",
        "\n",
        "Résultats :\n",
        "- Aucune valeur NULL n’a été détectée sur ces colonnes.\n",
        "- Toutes les lignes possèdent des informations complètes.\n",
        "\n",
        "Conclusion :\n",
        "La table ne présente pas de problème de valeurs manquantes sur les champs clés.\n",
        "Aucune action de nettoyage n’est nécessaire à ce niveau pour la couche gold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\moham\\Master 2 - CS\\BigData\\ProjetFinal\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Exemple : Agrégation des validations ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>JOUR</th>\n",
              "      <th>CATEGORIE_TITRE</th>\n",
              "      <th>total_validations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>91125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>Autres titres</td>\n",
              "      <td>313944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>NON DEFINI</td>\n",
              "      <td>94811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>Forfaits courts</td>\n",
              "      <td>19618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>Forfait Navigo</td>\n",
              "      <td>1545278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>Imagine R</td>\n",
              "      <td>704032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>Contrat Solidarité Transport</td>\n",
              "      <td>458234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>Contrat Solidarité Transport</td>\n",
              "      <td>360732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>NON DEFINI</td>\n",
              "      <td>76797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>Forfait Navigo</td>\n",
              "      <td>1140230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>Autres titres</td>\n",
              "      <td>248389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>Forfaits courts</td>\n",
              "      <td>12353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>72409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>Imagine R</td>\n",
              "      <td>526337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2023-07-03</td>\n",
              "      <td>Autres titres</td>\n",
              "      <td>370028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2023-07-03</td>\n",
              "      <td>Forfait Navigo</td>\n",
              "      <td>2957930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2023-07-03</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>115256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2023-07-03</td>\n",
              "      <td>Forfaits courts</td>\n",
              "      <td>22321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2023-07-03</td>\n",
              "      <td>Imagine R</td>\n",
              "      <td>1035922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2023-07-03</td>\n",
              "      <td>Contrat Solidarité Transport</td>\n",
              "      <td>677523</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          JOUR               CATEGORIE_TITRE  total_validations\n",
              "0   2023-07-01                     Amethyste              91125\n",
              "1   2023-07-01                 Autres titres             313944\n",
              "2   2023-07-01                    NON DEFINI              94811\n",
              "3   2023-07-01               Forfaits courts              19618\n",
              "4   2023-07-01                Forfait Navigo            1545278\n",
              "5   2023-07-01                     Imagine R             704032\n",
              "6   2023-07-01  Contrat Solidarité Transport             458234\n",
              "7   2023-07-02  Contrat Solidarité Transport             360732\n",
              "8   2023-07-02                    NON DEFINI              76797\n",
              "9   2023-07-02                Forfait Navigo            1140230\n",
              "10  2023-07-02                 Autres titres             248389\n",
              "11  2023-07-02               Forfaits courts              12353\n",
              "12  2023-07-02                     Amethyste              72409\n",
              "13  2023-07-02                     Imagine R             526337\n",
              "14  2023-07-03                 Autres titres             370028\n",
              "15  2023-07-03                Forfait Navigo            2957930\n",
              "16  2023-07-03                     Amethyste             115256\n",
              "17  2023-07-03               Forfaits courts              22321\n",
              "18  2023-07-03                     Imagine R            1035922\n",
              "19  2023-07-03  Contrat Solidarité Transport             677523"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Exemple 3 : Agrégation des validations\n",
        "\n",
        "TABLE_FACT = \"fact_validations_2023_s2_nb_fer_txt\"\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  JOUR,\n",
        "  CATEGORIE_TITRE,\n",
        "  SUM(NB_VALD) AS total_validations\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_FACT}`\n",
        "GROUP BY JOUR, CATEGORIE_TITRE\n",
        "ORDER BY JOUR\n",
        "LIMIT 20\n",
        "\"\"\"\n",
        "\n",
        "df_aggregation = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Exemple : Agrégation des validations ===\")\n",
        "display(df_aggregation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enfin, nous avons réalisés une agrégation sur la table des validations pour analyser le volume total de validations\n",
        "par **jour** et par **catégorie de titre**.\n",
        "\n",
        "Les données ont été regroupées selon :\n",
        "- la date (JOUR)\n",
        "- la catégorie de titre (CATEGORIE_TITRE)\n",
        "\n",
        "Pour chaque groupe, nous avons calculés le nombre total de validations.\n",
        "\n",
        "Résultats observés :\n",
        "- Certaines catégories comme `Forfait Navigo` et `Imagine R` présentent un volume de validations très élevé.\n",
        "- Les volumes varient fortement d’un jour à l’autre.\n",
        "- Cette agrégation permet d’identifier les titres les plus utilisés selon la période.\n",
        "\n",
        "Pour conclure, cette transformation est pertinente pour la couche gold, car elle permet de produire des indicateurs\n",
        "simples et exploitables pour l’analyse métier (suivi journalier, comparaison entre titres, tableaux de bord).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tâche 3 : Identifier les Clés de Jointure Possibles\n",
        "\n",
        "### Objectif\n",
        "\n",
        "Identifier toutes les **relations possibles** entre les tables pour pouvoir créer des jointures dans la couche gold.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Pour chaque paire de tables, identifiez :\n",
        "\n",
        "1. **Les colonnes de jointure** (clés étrangères)\n",
        "2. **Le type de relation** (1-1, 1-N, N-N)\n",
        "3. **La cardinalité** (combien de lignes de la table A correspondent à combien de lignes de la table B)\n",
        "4. **Vérifier l'intégrité référentielle** (toutes les clés étrangères existent-elles dans la table de dimension ?)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Jointure fact_validations VS dim_gare**\n",
        "\n",
        "- Clé de jointure :\n",
        "  - fact_validations.ID_ZDC\n",
        "  - dim_gare.id_ref_zdc\n",
        "\n",
        "- Type de relation : 1–N  \n",
        "  une gare peut avoir plusieurs validations\n",
        "\n",
        "- Cardinalité :\n",
        "  - 1 gare → N validations\n",
        "\n",
        "- Intégrité référentielle :\n",
        "  Les identifiants `ID_ZDC` présents dans la table de faits doivent exister dans la table `dim_gare`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Jointure fact_validations VS dim_ligne**\n",
        "\n",
        "- Clé de jointure :\n",
        "  - fact_validations.CODE_STIF_LIGNE\n",
        "  - dim_ligne.id_ligne\n",
        "\n",
        "- Type de relation : 1–N\n",
        "\n",
        "- Cardinalité :\n",
        "  - 1 ligne → plusieurs validations\n",
        "\n",
        "- Intégrité référentielle :\n",
        "  Les codes de ligne présents dans la table de faits doivent exister dans la table `dim_ligne`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Jointure fact_validations VS dim_arret**\n",
        "\n",
        "- Clé de jointure :\n",
        "  - fact_validations.CODE_STIF_ARRET\n",
        "  - dim_arret.arrid\n",
        "\n",
        "- Type de relation : 1–N\n",
        "\n",
        "- Cardinalité :\n",
        "  - 1 arrêt → plusieurs validations\n",
        "\n",
        "- Intégrité référentielle :\n",
        "  Les identifiants d’arrêt présents dans la table de faits doivent exister dans `dim_arret`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Jointure fact_validations VS dim_vacances_scolaires**\n",
        "\n",
        "- Clé de jointure :\n",
        "  - fact_validations.JOUR\n",
        "  - dim_vacances_scolaires.start_date / end_date\n",
        "\n",
        "- Type de relation : N–1\n",
        "\n",
        "- Cardinalité :\n",
        "  - plusieurs validations peuvent appartenir à une même période scolaire\n",
        "\n",
        "- Intégrité référentielle :\n",
        "  La date JOUR doit être comprise dans une période définie dans la table `dim_vacances_scolaires`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Jointure fact_validations VS dim_transporteur**\n",
        "\n",
        "- Clé de jointure :\n",
        "  - fact_validations.operatorref\n",
        "  - dim_transporteur.operatorref\n",
        "\n",
        "- Type de relation : 1–N\n",
        "\n",
        "- Cardinalité :\n",
        "  - un transporteur gère plusieurs validations\n",
        "\n",
        "- Intégrité référentielle :\n",
        "  Les opérateurs présents dans la table de faits doivent exister dans `dim_transporteur`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tâche 4 : Analyse métier\n",
        "\n",
        "Identifier les **KPIs** (Key Performance Indicators) à calculer :\n",
        "- Nombre total de validations par période\n",
        "- Répartition par type de titre\n",
        "- Top 10 des gares les plus fréquentées\n",
        "- Comparaison jour ouvrable vs weekend\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici, nous identifierons les indicateurs clés (KPI) qui peuvent être utilisés pour analyser l’utilisation du réseau SNCF.\n",
        "\n",
        "**1. Nombre total de validations par période**\n",
        "\n",
        "On peut calculer le nombre total de validations par:\n",
        "- jour\n",
        "- mois\n",
        "- année\n",
        "\n",
        "Cela permet d’observer l’évolution de la fréquentation dans le temps \n",
        "et d’identifier les périodes de forte ou faible affluence.\n",
        "\n",
        "\n",
        "**2. Répartition des validations par type de titre**\n",
        "\n",
        "Il est possible d’analyser les validations selon le type de titre \n",
        "(Forfait Navigo, etc.).\n",
        "\n",
        "Cette analyse permet de comprendre par exemple:\n",
        "- quels titres sont les plus utilisés\n",
        "- quels types d’usagers utilisent le réseau\n",
        "\n",
        "\n",
        "**3. Les 10 gares les plus fréquentées**\n",
        "\n",
        "On peut identifier les 10 gares qui ont le plus grand nombre de validations.\n",
        "\n",
        "Cela permet par exemple:\n",
        "- de repérer les gares les plus fréquentées\n",
        "- d’aider à la gestion du trafic et des infrastructures\n",
        "\n",
        "**4. Comparaison jours ouvrables vs week-end**\n",
        "\n",
        "Il est possible de comparer le nombre de validations :\n",
        "- les jours de semaine\n",
        "- les week-ends\n",
        "\n",
        "Cette comparaison permet de mieux comprendre les comportements des usagers \n",
        "selon quel jour on est."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
